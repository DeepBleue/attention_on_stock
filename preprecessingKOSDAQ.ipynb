{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from util.util import *\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- KOSDAQ 2013 processing -----------\n",
      "Number of NaN values: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0594f991ebc4f6c830d2ae10a35f238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- KOSDAQ 2014 processing -----------\n",
      "Number of NaN values: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222c0ceaba7f4d308253127b5e6d519b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- KOSDAQ 2015 processing -----------\n",
      "Number of NaN values: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d1688f5f2f4a63b755d881de05efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- KOSDAQ 2016 processing -----------\n",
      "Number of NaN values: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01ee4ffd20244928417e6441cfc4f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- KOSDAQ 2017 processing -----------\n",
      "Number of NaN values: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6633a16c21d4732855253beec47380b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pari0\\Desktop\\beta\\preprecessingKOSDAQ.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pari0/Desktop/beta/preprecessingKOSDAQ.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m label \u001b[39m=\u001b[39m data_21_rate\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pari0/Desktop/beta/preprecessingKOSDAQ.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m X \u001b[39m=\u001b[39m temp[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pari0/Desktop/beta/preprecessingKOSDAQ.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m norm_X \u001b[39m=\u001b[39m normalize_data_per_ticker_new(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pari0/Desktop/beta/preprecessingKOSDAQ.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m train_x\u001b[39m.\u001b[39mappend(norm_X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pari0/Desktop/beta/preprecessingKOSDAQ.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m train_y\u001b[39m.\u001b[39mappend(label)\n",
      "File \u001b[1;32mc:\\Users\\pari0\\Desktop\\beta\\util\\util.py:141\u001b[0m, in \u001b[0;36mnormalize_data_per_ticker_new\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    138\u001b[0m             data[ticker, :, i] \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m100.0\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[39melif\u001b[39;00m feature \u001b[39min\u001b[39;00m z_score_features : \n\u001b[1;32m--> 141\u001b[0m             data[ticker, :, i] \u001b[39m=\u001b[39m z_score_scaler\u001b[39m.\u001b[39;49mfit_transform(data[ticker, :, i]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    143\u001b[0m \u001b[39m# Identifying indices of features to remove\u001b[39;00m\n\u001b[0;32m    144\u001b[0m remove_indices \u001b[39m=\u001b[39m [feature_names\u001b[39m.\u001b[39mindex(feat) \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m remove_feature \u001b[39mif\u001b[39;00m feat \u001b[39min\u001b[39;00m feature_names]\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1006\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1003\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1005\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m-> 1006\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1007\u001b[0m     X,\n\u001b[0;32m   1008\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1009\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1010\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1011\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m   1012\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[0;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1016\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\utils\\validation.py:986\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 986\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    987\u001b[0m             array, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, xp\u001b[39m=\u001b[39;49mxp\n\u001b[0;32m    988\u001b[0m         )\n\u001b[0;32m    989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    990\u001b[0m     \u001b[39m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     array \u001b[39m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    992\u001b[0m         array, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, xp\u001b[39m=\u001b[39mxp\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pari0\\anaconda3\\envs\\alpha\\lib\\site-packages\\sklearn\\utils\\_array_api.py:378\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    376\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49marray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    379\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "market = 'KOSDAQ'\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019','2020','2021','2022','2023']\n",
    "\n",
    "# years = ['2017']\n",
    "\n",
    "for year in years : \n",
    "    print(f'----------- {market} {year} processing -----------')\n",
    "    with open(f'./data/{market}/{market}_{year}.pkl', 'rb') as f:\n",
    "        KOSPI_data = pickle.load(f)\n",
    "        \n",
    "    data = KOSPI_data['data']\n",
    "    valid_ticker = KOSPI_data['valid_ticker']\n",
    "    dimension = KOSPI_data['dimension']\n",
    "    features = KOSPI_data['features']\n",
    "    dates = KOSPI_data['dates']\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    tickers_num, time_step, features_dim = data.shape\n",
    "\n",
    "    window = 21\n",
    "\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "        \n",
    "    # print(len(data))\n",
    "    num_nan = np.isnan(data).sum()\n",
    "    print(\"Number of NaN values:\", num_nan)\n",
    "\n",
    "    # data = data[~np.isnan(data).any(axis=(1, 2))]\n",
    "    # print(len(data))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for i in tqdm(range(time_step-window),total= time_step-window):\n",
    "    \n",
    "        temp = data[:,i:i+window,:].copy()\n",
    "        day_20_close = temp[:,-2,3]\n",
    "        day_21_close = temp[:,-1,3]\n",
    "        data_21_rate = temp[:,-1,5]\n",
    "        # label = (day_21_close - day_20_close) / day_20_close \n",
    "        \n",
    "        label = data_21_rate\n",
    "\n",
    "        \n",
    "        X = temp[:,:-1,:]\n",
    "        \n",
    "\n",
    "\n",
    "        norm_X = normalize_data_per_ticker_new(X)\n",
    "\n",
    "        train_x.append(norm_X)\n",
    "        train_y.append(label)\n",
    "    train_x_save = np.concatenate(train_x, axis=0)\n",
    "    train_y_save = np.concatenate(train_y, axis=0)\n",
    "\n",
    "    np.save(f'./data/{market}/normalize_data/2/{market}_{year}_train_x_norm_close2close.npy', train_x_save)\n",
    "    np.save(f'./data/{market}/normalize_data/2/{market}_{year}_train_y_norm_close2close.npy', train_y_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
